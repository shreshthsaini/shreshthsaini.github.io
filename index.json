[{"authors":["admin"],"categories":null,"content":"I am Shreshth Saini, recently completed my B.Tech in Electrical Engineering from Indian Institue of Technology - Jodhpur. My research interests are highly interdisciplinary covering machine learning in general, application of deep learning in medical image analysis, biometrics and computer vision. I also work with memory based approaches for finacial data analysis. For a while, i have been trying to shift my focus towards unsupervised \u0026amp; reinforcement learnings.\nCurrently, I am working as a Research Engineer(AI). I have been working with Dr. Mengling \u0026lsquo;Mornin\u0026rsquo; Feng on skin cancer analysis using deep learning. At IIT Jodhpur, I was actively working with Dr. Anil Kumar Tiwari and Dr. Rajendra Nagar on multiple projects revolving around medical image analysis, image super resolution, etc. such as Segmentation of left atrium cavity in patients affected by atrial fibrillation. I also had the opportunity of woking with Dr. Aditya Nigam on application of deep learning in biometrics during my early days of exposure to the field of Deep learning and Applications.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://shreshthsaini.github.io/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"I am Shreshth Saini, recently completed my B.Tech in Electrical Engineering from Indian Institue of Technology - Jodhpur. My research interests are highly interdisciplinary covering machine learning in general, application of deep learning in medical image analysis, biometrics and computer vision. I also work with memory based approaches for finacial data analysis. For a while, i have been trying to shift my focus towards unsupervised \u0026amp; reinforcement learnings.\nCurrently, I am working as a Research Engineer(AI).","tags":null,"title":"Shreshth Saini","type":"authors"},{"authors":["Shreshth Saini","Divij Gupta","Ranjeet Ranjan Jha","Gaurav Jaswal","Aditya Nigam"],"categories":["Deep Learning","Biometrics"],"content":"","date":1598617739,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598617739,"objectID":"71526dca0e2f064bb4f89c794c451893","permalink":"https://shreshthsaini.github.io/publication/iris-segmentat-on-in-the-wild-using-encoder-decoder-based-deep-learningtechniques/","publishdate":"2020-08-28T17:58:59+05:30","relpermalink":"/publication/iris-segmentat-on-in-the-wild-using-encoder-decoder-based-deep-learningtechniques/","section":"publication","summary":"Iris recognition is considered to be one of the most widely used biometric modality, mainly due to its non-invasive nature and high reliability. However, in the whole process of authentication, segmentation of the iris is the most crucial one as being the second stage of the usual five-stage pipeline, the error introduced gets compounded in the subsequent stages. However, segmentation of the iris in non-ideal conditions is a challenging task owing to numerous artifacts such as occlusion by eyelids, off-angle rotations, irregular reflections, blurred boundaries, etc. Although the artifacts can be minimized up to a certain extent during the acquisition process, it requires a high level of control over the image capturing environment and also high user cooperation, which is not always feasible. For segmentation, quite a few methods have been put forward, but the ones using classical approaches usually have low generalisability. Over the past decade, various deep learning techniques have been proposed which have given satisfactory results. Since the problem at hand is that of an image-to-image generation(the input image and its corresponding segmentation mask), the most common similarity among them is the use of a standard encoder-decoder structure called the UNet. In this chapter, we discuss several such techniques and their intricate nov- elties, and shortcomings, while also throwing some light on the non-deep learning methods so as to get a wholesome comparison. We also discuss briefly about the various publicly available datasets and the artifacts they are riddled with while also discussing about the various metrics that are used by the scientific community to compare their works and es- tablish the state-of-the-art. Lastly, we discuss a short implementation of the UNet done by ourselves on two of the available datasets and conclude this chapter with a thought on the future possibilities of the existing works.","tags":["Deep Learning","Segmentation","UNet","Biometric","Iris"],"title":"Iris Segmentat on in the Wild Using Encoder Decoder Based Deep LearningTechniques","type":"publication"},{"authors":["Shreshth Saini","Divij Gupta","Anil Kumar Tiwari"],"categories":["Deep Learning","Medical Imaging Analysis"],"content":"This work has been accpeted at NCVPRIPG-19\n","date":1597420313,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1597420313,"objectID":"1beba45d3438d728e8c9811cf19b1779","permalink":"https://shreshthsaini.github.io/publication/detector-segmentor-network-for-skin-lesion-localization-and-segmentation/","publishdate":"2020-08-14T21:21:53+05:30","relpermalink":"/publication/detector-segmentor-network-for-skin-lesion-localization-and-segmentation/","section":"publication","summary":"Melanoma is a life-threatening form of skin cancer when left undiagnosed at the early stages. Although there are more cases of non-melanoma cancer than melanoma cancer, melanoma cancer is more deadly. Early detection of melanoma is crucial for the timely diagnosis of melanoma cancer and prohibit its spread to distant body parts. Segmentation of skin lesion is a crucial step in the classification of melanoma cancer from the cancerous lesions in dermoscopic images. Manual segmentation of dermoscopic skin images is very time consuming and error-prone resulting in an urgent need for an intelligent and accurate algorithm. In this study, we propose a simple yet novel network-in-network convolution neural network(CNN) based approach for segmentation of the skin lesion. A Faster Region-based CNN (Faster RCNN) is used for preprocessing to predict bounding boxes of the lesions in the whole image which are subsequently cropped and fed into the segmentation network to obtain the lesion mask. The segmentation network is a combination of the UNet and Hourglass networks. We trained and evaluated our models on ISIC 2018 dataset and also crossvalidated on PH2 and ISBI 2017 datasets. Our proposed method surpassed the state-of-the-art with Dice Similarity Coefficient of 0.915 and Accuracy 0.959 on ISIC 2018 dataset and Dice Similarity Coefficient of 0.947 and Accuracy 0.971 on ISBI 2017 dataset","tags":["CNN","Faster RCNN","Segmentation","Dermoscopic","Melanoma","Dice Similarity Coefficient"],"title":"Detector-SegMentor Network for Skin Lesion Localization and Segmentation","type":"publication"},{"authors":["Shreshth Saini"],"categories":["ML"],"content":" What does Support Vector Machines do? Support Vector Machines are supervised learning models for classification and regression problems. They can solve linear and non-linear problems and work well for many practical problems. The idea of Support Vector Machines is simple: The algorithm creates a line which separates the classes in case e.g. in a classification problem. The goal of the line is to maximizing the margin between the points on either side of the so called decision line. The benefit of this process is, that after the separation, the model can easily guess the target classes (labels) for new cases.\nMaybe you say now, that this probably only works for a low dimensional problem, e.g a data set with only 2 features, but that is wrong! Support Vector Machines are actually very effective in higher dimensional spaces. It is even very effective on data sets where number of dimensions is greater than the number of samples. This is mainly because of the kernel trick, which we talk about it later. Further advantages of Support Vector Machines are the memory efficiency, speed and general accuracy in comparison to other classification methods like k-nearest neighbor or deep neural networks. Of course they are not every time better than e.g. deep neural networks, but sometimes they still outperform deep neural networks. SVM is based on the idea of finding a hyperplane that best separates the features into different domains.\nDifference between Linear and Non-Linear Data To clear everything up, I explain quickly what it is all about the linear and non-linear data thing. We talk about linear data, when we can classify the data with a linear classifier. The linear classifier makes his classification decision based on a linear combination of characteristics. The characteristics are also known as features in machine learning. The following picture will make things more clear.\nIn figure A we can separate the target labels linear with a line (like Support Vector Machines do classification with a decision line). A linear classifier can do this with a linear combination of characteristics. We could use e.g. Support Vector Machines do build a model, but we could also use many other linear classification methods like quadratic classification. In figure B we can not separate the target labels linear. The data is more complex divided. Therefore we can not just use a linear classification method. Fortunately Support Vector Machines can do both, linear and non-linear classification. Lets first take an easier linear example to get an introduction about Support Vector Machines. Later we will look at non-linear classification with Support Vector Machines and we will see how it works with the kernel trick.\nIntuition development Consider a situation following situation: There is a stalker who is sending you emails and now you want to design a function( hyperplane ) which will clearly differentiate the two cases, such that whenever you received an email from the stalker it will be classified as a spam. The following are the figure of two cases in which the hyperplane are drawn, which one will you pick and why? take a moment to analyze the situation below.\nI guess you would have picked the fig(a). Did you think why have you picked the fig(a)? Because the emails in fig(a) are clearly classified and you are more confident about that as compared to fig(b). Basically, SVM is composed of the idea of coming up with an Optimal hyperplane which will clearly classify the different classes(in this case they are binary classes).\nTerminologies used in SVM: The points closest to the hyperplane are called as the support vector points and the distance of the vectors from the hyperplane are called the margins.\nThe basic intuition to develop over here is that more the farther SV points, from the hyperplane, more is the probability of correctly classifying the points in their respective region or classes. SV points are very critical in determining the hyperplane because if the position of the vectors changes the hyperplane’s position is altered. Technically this hyperplane can also be called as margin maximizing hyperplane.\nHyperplane(Decision surface ): For so long in this post we have been discussing the hyperplane, let’s justify its meaning before moving forward. The hyperplane is a function which is used to differentiate between features. In 2-D, the function used to classify between features is a line whereas, the function used to classify the features in a 3-D is called as a plane similarly the function which classifies the point in higher dimension is called as a hyperplane. Now since you know about the hyperplane lets move back to SVM.\nLet’s say there are “m” dimensions: thus the equation of the hyperplane in the ‘M’ dimension can be given as =\nwhere, Wi = vectors(W0,W1,W2,W3……Wm), b = biased term (W0), X = variables.\nHard margin SVM: Now, Assume 3 hyperplanes namely (π, π+, π−) such that ‘π+’ is parallel to ‘π’ passing through the support vectors on the positive side and ‘π−’ is parallel to ‘π’ passing through the support vectors on the negative side.\nthe equations of each hyperplane can be considered as:\nfor the point X1 :\nExplanation: when the point X1 we can say that point lies on the hyperplane and the equation determines that the product of our actual output and the hyperplane equation is 1 which means the point is correctly classified in the positive domain. for the point X3:\nExplanation: when the point X3 we can say that point lies away from the hyperplane and the equation determines that the product of our actual output and the hyperplane equation is greater 1 which means the point is correctly classified in the positive domain. for the point X4:\nExplanation: when the point X4 we can say that point lies on the hyperplane in the negative region and the equation determines that the product of our actual output and the hyperplane equation is equal to 1 which means the point is correctly classified in the negative domain. for the point X6 :\nExplanation: when the point X6 we can say that point lies away from the hyperplane in the negative region and the equation determines that the product of our actual output and the hyperplane equation is greater 1 which means the point is correctly classified in the negative domain. Let’s look into the constraints which are not classified:\nfor point X7:\nExplanation: When Xi = 7 the point is classified incorrectly because for point 7 the wT + b will be smaller than one and this violates the constraints. So we found the misclassification because of constraint violation. Similarly, we can also say for points Xi = 8. Thus from the above examples, we can conclude that for any point Xi, if Yi(WT*Xi +b) ≥ 1: then Xi is correctly classified else: Xi is incorrectly classified. So we can see that if the points are linearly separable then only our hyperplane is able to distinguish between them and if any outlier is introduced then it is not able to separate them. So these type of SVM is called as hard margin SVM (since we have very strict constraints to correctly classify each and every datapoint).\nSoft margin SVM: We basically consider that the data is linearly separable and this might not be the case in real life scenario. We need an update so that our function may skip few outliers and be able to classify almost linearly separable points. For this reason, we introduce a new Slack variable ( ξ ) which is called Xi. if we introduce ξ it into our previous equation we can rewrite it as\nif ξi= 0, the points can be considered as correctly classified. else: ξi\u0026gt; 0 , Incorrectly classified points. so if ξi\u0026gt; 0 it means that Xi(variables)lies in incorrect dimension, thus we can think of ξi as an error term associated with Xi(variable). The average error can be given as;\nthus our objective, mathematically can be described as;\nwhere ξi = ςi\nThis formulation is called the Soft margin technique.\nLoss Function Interpretation of SVM: it can be interpreted that hinge loss is max(0,1-Zi).\nwhen Zi is ≥ 1 then the loss is 0. when Zi \u0026lt; 1 then loss increases.\nWhat is Kernel trick? Coming to the major part of the SVM for which it is most famous, the kernel trick. The kernel is a way of computing the dot product of two vectors x and y in some (very high dimensional) feature space, which is why kernel functions are sometimes called “generalized dot product.\nApplying kernel trick means just to the replace dot product of two vectors by the kernel function.\nUsing the Support Vector Machines for non-linear data with the kernel trick Until know we have talked about linear examples and how Support Vector Machines work and how you can implement them with sklearn in Python. I already talked a little bit about non-linear data. When there is a non-linear data set Support Vector Machines can not simply draw a linear hyperplane. Therefore Support Vector Machines use the kernel trick. When you have non-linear data, the kernel method helps you to find pattern and relations to reach a high accuracy in your final machine learning model.\nHow does the Kernel method works? The kernel method are contains are so called kernel function. These function map the non-linear separable input space into a higher dimensional linear separable feature space. And in this new higher dimensional linear separable feature space Support Vector Machines can work as normal. The kernel method then maps the solutions back, so that in the non-linear separable input space you then have a non-linear solution.\nIn the example above we have a two dimensional feature space, which is non-linear. With the kernel function we can map the input space into a three dimensional feature space. In this feature space we then can separate the training set linear. When we map the solution back to the input space we get a non-linear solution.\nPros and cons of SVM: Pros: * It is really effective in the higher dimension * Effective when the number of features are more than training examples * Best algorithm when classes are separable * The hyperplane is affected by only the support vectors thus outliers have less impact * SVM is suited for extreme case binary classification cons: * For larger dataset, it requires a large amount of time to process * Does not perform well in case of overlapped classes * Selecting, appropriately hyperparameters of the SVM that will allow for sufficient generalization performance * Selecting the appropriate kernel function can be tricky\nPreparing data for SVM:  Numerical Conversion: SVM assumes that you have inputs are numerical instead of categorical. So you can convert them using one of the most commonly used “one hot encoding , label-encoding etc”. Binary Conversion: Since SVM is able to classify only binary data so you would need to convert the multi-dimensional dataset into binary form using (one vs the rest method / one vs one method) conversion method.  REFERENCES:  http://cs229.stanford.edu/notes/cs229-notes3.pdf (Andrew Ng’s notes on SVM) https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html (Sklearn page on SVM)  ","date":1583142745,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1583142745,"objectID":"039a5aded1ea3595932b885cc9d1a1b6","permalink":"https://shreshthsaini.github.io/post/svm/","publishdate":"2020-03-02T15:22:25+05:30","relpermalink":"/post/svm/","section":"post","summary":"A Support Vector Machine (SVM) is a discriminative classifier formally defined by a separating hyperplane. In other words, given labeled training data (supervised learning), the algorithm outputs an optimal hyperplane which categorizes new examples. In two dimentional space this hyperplane is a line dividing a plane in two parts where in each class lay in either side","tags":["ML","SVM","Classification","Tool"],"title":"Supprt Vector Machine (SVM)","type":"post"},{"authors":["Shreshth Saini"],"categories":[],"content":" What is Genome Sequencing? Genome sequencing or DNA sequencing refers to the process of determining the complete sequence of nucleotides in genome (read DNA). Ignoring the 3 dimensional orientation of the DNA strand, DNA can be thought of as a linear sequence of 4 nucleotide base pairs (bp), namely Adenine (A), Thymine (T), Guanine (G), Cytosine (C). A pairs with T and G pairs with C. Sequencing allows us to determine the sequence such as AATGCCAT\u0026hellip;.\nWhy is sequencing important? Have you heard of Precision Medicine (PM)?\nThink about it this way, everytime you face a serious medical issue, instead of prescribing generic medicine/treatment procedures which is given to all the patient with similar symptoms, you get a prescription tailored for you, by analysing your genetic code and symptoms. The exact same treatment for exact same symptoms on me and you might have different outcomes, it may not be pleasant for one of us.\nNow to enable precision medicine, one of the key steps is to create profile for the patient, which is where sequencing comes into picture. Therfore it is important to invest and develope sequencing methods which have higher accuracies and are faster and cheaper.\ncheck out this video for one success story of precision medicine\nHow is sequencing done? Attempts to sequence DNA dates back to 1970s (wikipedia link to brief history). Intital techniques, even though impressive were quite costly and terribly slow for real world applications such as using it for human genome. Humans have come a long way now, both time and costs to sequence whole genome has come down drastically and now it\u0026rsquo;s practical to think about genome sequencing as part of diagnostics.\nRecent techniques are known as NGS (Next Generation Sequencing) or HTS (High Throughput Sequencing). In the following I will discuss one successful commercial technique used today. While reading up on this topic I realised that the literature around this topic is presented with alot of fancy words (that made no sense to me and will probably not make sense to average joe). But then the topic is quite specific and not meant for avaerage joe, however to grasp things I found it helpful to look around for the meaning of fancy words as they help in providing context and fill in the gaps. I will try to present it in a simple language with links to resources where necessary.\nDNA Nanoball Sequencing Many of the sequencing method will broadly involve steps such as\n splitting the DNA strand into smaller pieces generating multiple copies of the smaller pieces processing the cluster of smaller pieces with marker nucleotides which are fluorescent and are color coded depending upon the nucleotide capturing the image/data bioinformatics on data to extract sequences  The specifics of each of the steps depend upon the method used. In DNA Nanoball Sequencing the longer DNA strands are sonicated (using sound) to break them into smaller pieces, then pieces of appropriate lengths (typically 400-500 bp) are chosen for futher processing (how it\u0026rsquo;s done is irrelevant for the conceptual big picture).\nHere is a cool video showing the sonification process\n\nNest step involves attaching adapter sequences and to convert the small fragments into curcular struture which is then replicated by a procedure call Rolling circle replication. The output of this step leads to lot of circular copies which when linearised, forms a long strand of DNA, because of the adapter sequences (desinged to be \u0026ldquo;sticky\u0026rdquo;) the long strand folds onto itself making a ball like structure which is about 300nm in diameter. These nanoballs are then attached to a specially constructed microarray, nanoballs are arranged in highly ordered fashion hence are densly packed which is what allows the massive parallel processing. One way to think about these arrays:\nThe sequencing part is easier to analyse with the unchained visualisation, that is consider the image of long DNA strand from the nanoball, we know the adapter sequences which we attached earlier, so we can construct an \u0026ldquo;anchor\u0026rdquo; sequence which will attach to the adapter part of the long template strand.\nNow we introduce, something called \u0026ldquo;probes\u0026rdquo;, these are short sequences with \u0026ldquo;degenerate (not important)\u0026rdquo; nucleotides in all but one position, and have a color coded floroscence depending upon that one non-denerate nucleotide (for example in the image, A is red, C is yellow, G is green, T is blue).\nAnchor is attached to the adapter sequence, the microarray cell is flooded with one type of probes (say non-degenrate nucleotide at one position to the left of adapter part), only the probe containing the complimentary non-degenrate nucleotide will bind, we can wash away the redundant chemicals and record the florocent signals, the color will indicate which one of the A/T/G/C was present at that location. We can wash away the anchor and probe of this round and repeat the process with probes of different locations. As described nicely in this image and its caption :\n1. Single strand of DNA from a DNA nanoball 2. Attach complementary anchor to known adapter sequence 3. Add probe set #1 and DNA Ligase to interrogate position #1 to the left of the anchor. Only the complementary probe binds 4. Wash away all unbound probes and Ligase, and read the color of the fluorophore 5. Denature anchor and probe from DNA nanoball and add another anchor 6. Add probe set #2 and DNA ligase to interrogate position #2 to the left of the anchor. Repeat.\nThis is an iterative process, where after every round of probe/ligation step, excessive chemicals are washed and the fluorocence is captured in form of a image. These images are then analysed to infer the sequence of the template strand using the colour coding scheme of the nucleotides.\nI chose this method because it is at the crux of commecial product by Beijing Genomics Institute (BGI). Their method is known as Combinatorial probe anchor synthesis (cPAS), the technology is capable of processing around 40 million nucleotides per second (as of 2018, which is a remarkable number)\nReferences  http://www.genomenewsnetwork.org/resources/whats_a_genome/Chp2_1.shtml https://www.ebi.ac.uk/training/online/course/ebi-next-generation-sequencing-practical-course/what-you-will-learn/what-next-generation-dna- https://en.wikipedia.org/wiki/DNA_sequencing https://en.wikipedia.org/wiki/DNA_nanoball_sequencing http://www.seq500.com/en/portal/Seq-500.shtml https://en.wikipedia.org/wiki/Sonication https://www.creative-biogene.com/blog/index.php/2016/11/01/brief-introduction-on-three-generations-of-genome-sequencing-technology/ http://koreabizwire.com/scientists-find-whole-genome-sequencing-of-korean-individual/67503  ","date":1566153000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1566153000,"objectID":"8e8ed2f798664bd1cbc5f1812d5070cd","permalink":"https://shreshthsaini.github.io/post/genome-sequencing/","publishdate":"2019-08-19T00:00:00+05:30","relpermalink":"/post/genome-sequencing/","section":"post","summary":"Sequencing of genomes is an important land mark that humanity has achieved as it opens door to various explorations such as understanding life at a very fundamental level and Precision Medicine which can have the great impact on everyone's life, this post reflects my understanding of genome sequencing and some methods to do the same","tags":[],"title":"Genome sequencing","type":"post"},{"authors":[],"categories":["Deep Learning","Biometrics"],"content":"","date":1559759400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1559759400,"objectID":"b18344129afe51559bfcccb5bbedc0c2","permalink":"https://shreshthsaini.github.io/publication/pixlsegnet/","publishdate":"2019-06-06T00:00:00+05:30","relpermalink":"/publication/pixlsegnet/","section":"publication","summary":"Biometric segmentation to obtain the region of interest under non-cooperative conditions is a fundamental and essential problem in biometric research. In the past few decades, researchers have widely studied this problem. For instance, non-ideal iris images cause poor segmentation in case of non-regular reflections, blurred boundaries, eyelids occlusion, and off-angle rotations. In this paper, we present a new iris ROI segmentation algorithm using a deep convolutional neural network to achieve the state-of-the-art segmentation performance on well-known iris image datasets. Our model surpasses the performance of state- of-the-art Iris-DenseNet framework by applying several strategies, including multi-scale/ multi-orientation training, model training from scratch, and proper hyper-parameterization of crucial parameters. The proposed PixISegNet consists of an autoencoder which primarily uses long and short skip connections and a stacked hourglass network between encoder and decoder. There is a continuous scale up-down in stacked hourglass networks, which helps in extracting features at multiple scales and robustly segments the iris even in an occluded environment. Furthermore, cross entropy loss and content loss optimizes the proposed model. The content loss considers the high-level features, thus operating at a different scale of abstraction, which compliments the cross-entropy loss, which considers pixel-to-pixel classification loss. Additionally, we have checked the robustness of the proposed network by rotating images to certain degrees with a change in the aspect ratio along with blurring and change in contrast. Experimental results on the various iris characteristics demonstrate the superiority of the proposed method over state-of-the-art iris segmentation methods considered in this paper. In order to demonstrate the network generalization, we deploy a very stringent T OT A (i.e train once test all) strategy. Our proposed method achieves E1 scores of 0.00672, 0.00916 and 0.00117 on UBIRIS-V2, IIT-D and CASIA V3.0 Interval datasets respectively. Moreover, such a deep convolutional neural network for segmentation when included in an end-to-end iris recognition system with a siamese based matching network will augment the performance of the siamese network. It facilitates the siamese matching network by selectively removing all of the unwanted (non-iris) pixels, to learn the salient iris features and provide a better recognition performance.","tags":["CNN","Segmentation","Biometric","Iris","Non-ideal","Dice Similarity Coefficient"],"title":"PixISegNet: Pixel Level Iris Segmentation Network using Convolutional Encoder-Decoder with Stacked Hourglass Bottleneck","type":"publication"},{"authors":null,"categories":null,"content":"This summarizes my work at my first ever internship at Julia Computing during the winter breaks of 2016 (Nov-2016 to Jan-2017). I wrote julia scripts to load big datasets efficiently and perform unsupervised learning tasks such as Nearest-Neighbour clusterring and supervised learning tasks such as Generalized linear models for predicting the costs and journey time given relevant variables and location. To create some cool visualizations and of valuable insight I used google maps api!\n","date":1453222062,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1453222062,"objectID":"0f62c7f7bc7903daea038de6f55b13a0","permalink":"https://shreshthsaini.github.io/project/ny_taxi/","publishdate":"2016-01-19T22:17:42+05:30","relpermalink":"/project/ny_taxi/","section":"project","summary":"Julia scripts to process, analyze and visualize the results of New York taxi dataset","tags":[],"title":"New York Taxi Analysis","type":"project"}]