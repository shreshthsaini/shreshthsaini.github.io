<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts | meliorate</title>
    <link>https://shreshthsaini.github.io/post/</link>
      <atom:link href="https://shreshthsaini.github.io/post/index.xml" rel="self" type="application/rss+xml" />
    <description>Posts</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>© 2020</copyright><lastBuildDate>Mon, 31 Aug 2020 20:06:52 +0530</lastBuildDate>
    <image>
      <url>https://shreshthsaini.github.io/img/icon-192.png</url>
      <title>Posts</title>
      <link>https://shreshthsaini.github.io/post/</link>
    </image>
    
    <item>
      <title>Variational AutoEncoder</title>
      <link>https://shreshthsaini.github.io/post/variational-autoencoder/</link>
      <pubDate>Mon, 31 Aug 2020 20:06:52 +0530</pubDate>
      <guid>https://shreshthsaini.github.io/post/variational-autoencoder/</guid>
      <description>

&lt;p&gt;In the last few years deep learning practictioners have developed a huge interest in deep generative models. Credit for this can be given to availability of huge datasets, computational capacity, efficient optimization methods and well-designed networks. With all these, generative model are now able to produce realistic contents be it images, texts or voice/music. In this post I have tried to present my understandig of one such generative approach : Variational Auto-Encoder.&lt;/p&gt;

&lt;h3 id=&#34;auto-encoders&#34;&gt;Auto-Encoders&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;Before we actually dive into the Variational autoencoders, lets have a clarity about what are autoencoders.&lt;/em&gt;&lt;/strong&gt;
Autoencoder are used for data compression and other derivative tasks such as segmentation, noise reduction, feature manipulation in image, etc.. Autoencoder consists of two part namely &lt;strong&gt;&lt;em&gt;Encoder&lt;/em&gt;&lt;/strong&gt; and &lt;strong&gt;&lt;em&gt;Decoder&lt;/em&gt;&lt;/strong&gt;. Encoder(E) takes the input(X) and produces corresponding latent space representation(E(X)), output of encoder is then fed to decoder(D) which gives us our final output(D(E(X))). Autoencoder are trained supervisingly (X,Y). With convolutional autoencoder we can extract high dimensional representation of our data from latent space. For data compression latent is have fewer features (mainly with fully connected neural network design).&lt;/p&gt;

&lt;p&gt;| &lt;img src=&#34;autoencoder.jpg&#34; alt=&#34;autoencoder-sample.jpg&#34; /&gt; |
|:&amp;ndash;:|
| &lt;em&gt;1. Convolutional Autoencoder.&lt;a href=&#34;#1&#34;&gt;[1]&lt;/a&gt;&lt;/em&gt;  |&lt;/p&gt;

&lt;h3 id=&#34;variational-auto-encoders-vaes&#34;&gt;Variational Auto-Encoders(VAEs)&lt;/h3&gt;

&lt;p&gt;Having understood the basics of autoencoder and its structure now we can move towards the real thing. It it to be notes that latent space representations from simple autoencoder can not be used in generation task as it gives the a rather unrealistic output. Reason being distribution of latent space is often not continuous. Variational autonencoders introduce additional layers at bottleneck of the network to extract the probablistic distribution of the latent space (mean and variance), in additional a KL-Divergence loss &lt;a href=&#34;#2&#34;&gt;[2]&lt;/a&gt; is also used to bring the data distribution close up for interpolation inbetween the classes (generation). In general results of VAE are blurry, novel loss functions such as generative loss &lt;a href=&#34;#3&#34;&gt;[3]&lt;/a&gt; or perceptual loss &lt;a href=&#34;#4&#34;&gt;[4]&lt;/a&gt; can be used to remove the blurriness.&lt;/p&gt;

&lt;p&gt;| &lt;img src=&#34;vae.jpg&#34; alt=&#34;vae-sample.jpg&#34; /&gt; |
|:&amp;ndash;:|
| &lt;em&gt;2. Convolutional Variational Autoencoder. Low dimensional representation feature is sampled from learned distribution at bottlecneck. Unit gaussian distribution depicts convergence of learned distribution towards normal distribution.&lt;/em&gt;&lt;a href=&#34;#5&#34;&gt;[5]&lt;/a&gt; |&lt;/p&gt;

&lt;p&gt;###&lt;/p&gt;

&lt;h3 id=&#34;references&#34;&gt;REFERENCES:&lt;/h3&gt;

&lt;p&gt;&lt;a id=&#34;1&#34;&gt;[1]&lt;/a&gt;
&lt;a href=&#34;https://www.cs.umd.edu/sites/default/files/scholarly_papers/Larrue,%20Tara_1801.pdf&#34; target=&#34;_blank&#34;&gt;Tara Larrue and Xiaoxu Meng and Chang-Mu Han.
Denoising Videos with Convolutional Autoencoders A Comparison of Autoencoder Architectures, 2018.&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a id=&#34;2&#34;&gt;[2]&lt;/a&gt;
&lt;a href=&#34;https://doi.org/10.1007/978-3-642-04898-2_327&#34; target=&#34;_blank&#34;&gt;Joyce, James M., Lovric, Miodrag.
Kullback-Leibler Divergence. International Encyclopedia of Statistical Science
Springer Berlin Heidelberg. 720&amp;ndash;722, 978-3-642-04898-2. 2011
DOI:10.&lt;sup&gt;1007&lt;/sup&gt;&amp;frasl;&lt;sub&gt;978&lt;/sub&gt;-3-642-04898-2_327&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a id=&#34;3&#34;&gt;[3]&lt;/a&gt;
&lt;a href=&#34;https://arxiv.org/abs/1512.09300&#34; target=&#34;_blank&#34;&gt;Anders Boesen Lindbo Larsen, Søren Kaae Sønderby, Hugo Larochelle, Ole Winther.
Autoencoding beyond pixels using a learned similarity metric. 2016&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a id=&#34;4&#34;&gt;[4]&lt;/a&gt;
&lt;a href=&#34;https://arxiv.org/abs/1610.00291&#34; target=&#34;_blank&#34;&gt;Xianxu Hou, Linlin Shen, Ke Sun, Guoping Qiu.
Deep Feature Consistent Variational Autoencoder. 2016&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a id=&#34;5&#34;&gt;[5]&lt;/a&gt;
&lt;a href=&#34;https://iq.opengenus.org/types-of-autoencoder/&#34; target=&#34;_blank&#34;&gt;Abhinav Prakash.
Different types of Autoencoders. opengenus.org.
University of Massachusetts, Amherst.&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Supprt Vector Machine (SVM)</title>
      <link>https://shreshthsaini.github.io/post/svm/</link>
      <pubDate>Mon, 02 Mar 2020 15:22:25 +0530</pubDate>
      <guid>https://shreshthsaini.github.io/post/svm/</guid>
      <description>

&lt;h3 id=&#34;what-does-support-vector-machines-do&#34;&gt;What does Support Vector Machines do?&lt;/h3&gt;

&lt;p&gt;Support Vector Machines are supervised learning models for classification and regression problems. They can solve linear and non-linear problems and work well for many practical problems. The idea of Support Vector Machines is simple: The algorithm creates a line which separates the classes in case e.g. in a classification problem. The goal of the line is to maximizing the margin between the points on either side of the so called decision line. The benefit of this process is, that after the separation, the model can easily guess the target classes (labels) for new cases.&lt;/p&gt;

&lt;p&gt;Maybe you say now, that this probably only works for a low dimensional problem, e.g a data set with only 2 features, but that is wrong! Support Vector Machines are actually very effective in higher dimensional spaces. It is even very effective on data sets where number of dimensions is greater than the number of samples. This is mainly because of the kernel trick, which we talk about it later. Further advantages of Support Vector Machines are the memory efficiency, speed and general accuracy in comparison to other classification methods like k-nearest neighbor or deep neural networks. Of course they are not every time better than e.g. deep neural networks, but sometimes they still outperform deep neural networks. SVM is based on the idea of finding a hyperplane that best separates the features into different domains.&lt;/p&gt;

&lt;h3 id=&#34;difference-between-linear-and-non-linear-data&#34;&gt;Difference between Linear and Non-Linear Data&lt;/h3&gt;

&lt;p&gt;To clear everything up, I explain quickly what it is all about the linear and non-linear data thing. We talk about linear data, when we can classify the data with a linear classifier. The linear classifier makes his classification decision based on a linear combination of characteristics. The characteristics are also known as features in machine learning. The following picture will make things more clear.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;nonlinear.png&#34; alt=&#34;Linear vs NonLinear data examples&#34; /&gt;&lt;/p&gt;

&lt;p&gt;In figure A we can separate the target labels linear with a line (like Support Vector Machines do classification with a decision line). A linear classifier can do this with a linear combination of characteristics. We could use e.g. Support Vector Machines do build a model, but we could also use many other linear classification methods like quadratic classification.
In figure B we can not separate the target labels linear. The data is more complex divided. Therefore we can not just use a linear classification method. Fortunately Support Vector Machines can do both, linear and non-linear classification. Lets first take an easier linear example to get an introduction about Support Vector Machines. Later we will look at non-linear classification with Support Vector Machines and we will see how it works with the kernel trick.&lt;/p&gt;

&lt;h3 id=&#34;intuition-development&#34;&gt;&lt;em&gt;Intuition development&lt;/em&gt;&lt;/h3&gt;

&lt;p&gt;Consider a situation following situation:
There is a stalker who is sending you emails and now you want to design a function( hyperplane ) which will clearly differentiate the two cases, such that whenever you received an email from the stalker it will be classified as a spam. The following are the figure of two cases in which the hyperplane are drawn, which one will you pick and why? take a moment to analyze the situation below.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;classific.png&#34; alt=&#34;Exmaple Hyperplane&#34; /&gt;&lt;/p&gt;

&lt;p&gt;I guess you would have picked the fig(a). Did you think why have you picked the fig(a)? Because the emails in fig(a) are clearly classified and you are more confident about that as compared to fig(b). Basically, SVM is composed of the idea of coming up with an Optimal hyperplane which will clearly classify the different classes(in this case they are binary classes).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;Terminologies used in SVM:&lt;/em&gt;&lt;/strong&gt;
The points closest to the hyperplane are called as the support vector points and the distance of the vectors from the hyperplane are called the margins.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;supportv.png&#34; alt=&#34;Support Vectors&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The basic intuition to develop over here is that more the farther SV points, from the hyperplane, more is the probability of correctly classifying the points in their respective region or classes. SV points are very critical in determining the hyperplane because if the position of the vectors changes the hyperplane’s position is altered. Technically this hyperplane can also be called as margin maximizing hyperplane.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;Hyperplane(Decision surface ):&lt;/em&gt;&lt;/strong&gt;
For so long in this post we have been discussing the hyperplane, let’s justify its meaning before moving forward. The hyperplane is a function which is used to differentiate between features. In 2-D, the function used to classify between features is a line whereas, the function used to classify the features in a 3-D is called as a plane similarly the function which classifies the point in higher dimension is called as a hyperplane. Now since you know about the hyperplane lets move back to SVM.&lt;/p&gt;

&lt;p&gt;Let’s say there are “m” dimensions:
thus the equation of the hyperplane in the ‘M’ dimension can be given as =&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;eq1.png&#34; alt=&#34;Equation 1&#34; /&gt;&lt;/p&gt;

&lt;p&gt;where,
Wi = vectors(W0,W1,W2,W3……Wm),
b = biased term (W0),
X = variables.&lt;/p&gt;

&lt;h3 id=&#34;hard-margin-svm&#34;&gt;Hard margin SVM:&lt;/h3&gt;

&lt;p&gt;Now,
Assume 3 hyperplanes namely (π, π+, π−) such that ‘π+’ is parallel to ‘π’ passing through the support vectors on the positive side and ‘π−’ is parallel to ‘π’ passing through the support vectors on the negative side.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;phyper.png&#34; alt=&#34;Potential Hyoerplane&#34; /&gt;&lt;/p&gt;

&lt;p&gt;the equations of each hyperplane can be considered as:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;eq2.png&#34; alt=&#34;Equation 2&#34; /&gt;&lt;/p&gt;

&lt;p&gt;for the point X1 :&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;eq3.png&#34; alt=&#34;Equation 3&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Explanation: when the point X1 we can say that point lies on the hyperplane and the equation determines that the product of our actual output and the hyperplane equation is 1 which means the point is correctly classified in the positive domain.
for the point X3:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;eq4.png&#34; alt=&#34;Equation 4&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Explanation: when the point X3 we can say that point lies away from the hyperplane and the equation determines that the product of our actual output and the hyperplane equation is greater 1 which means the point is correctly classified in the positive domain.
for the point X4:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;eq5.png&#34; alt=&#34;Equation 5&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Explanation: when the point X4 we can say that point lies on the hyperplane in the negative region and the equation determines that the product of our actual output and the hyperplane equation is equal to 1 which means the point is correctly classified in the negative domain.
for the point X6 :&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;eq6.png&#34; alt=&#34;Equation 6&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Explanation: when the point X6 we can say that point lies away from the hyperplane in the negative region and the equation determines that the product of our actual output and the hyperplane equation is greater 1 which means the point is correctly classified in the negative domain.
Let’s look into the constraints which are not classified:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;phyper.png&#34; alt=&#34;Potential Hyperplane&#34; /&gt;&lt;/p&gt;

&lt;p&gt;for point X7:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;eq7.png&#34; alt=&#34;Equation 7&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Explanation: When Xi = 7 the point is classified incorrectly because for point 7 the wT + b will be smaller than one and this violates the constraints. So we found the misclassification because of constraint violation. Similarly, we can also say for points Xi = 8.
Thus from the above examples, we can conclude that for any point Xi,
if Yi(WT*Xi +b) ≥ 1:
then Xi is correctly classified
else:
Xi is incorrectly classified.
So we can see that if the points are linearly separable then only our hyperplane is able to distinguish between them and if any outlier is introduced then it is not able to separate them. So these type of SVM is called as hard margin SVM (since we have very strict constraints to correctly classify each and every datapoint).&lt;/p&gt;

&lt;h3 id=&#34;soft-margin-svm&#34;&gt;Soft margin SVM:&lt;/h3&gt;

&lt;p&gt;We basically consider that the data is linearly separable and this might not be the case in real life scenario. We need an update so that our function may skip few outliers and be able to classify almost linearly separable points. For this reason, we introduce a new Slack variable ( ξ ) which is called Xi.
if we introduce ξ it into our previous equation we can rewrite it as&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;eq8.png&#34; alt=&#34;Introduction of Xi&#34; /&gt;&lt;/p&gt;

&lt;p&gt;if ξi= 0,
the points can be considered as correctly classified.
else:
ξi&amp;gt; 0 , Incorrectly classified points.
so if ξi&amp;gt; 0 it means that Xi(variables)lies in incorrect dimension, thus we can think of ξi as an error term associated with Xi(variable). The average error can be given as;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;eq9.png&#34; alt=&#34;Average Error&#34; /&gt;&lt;/p&gt;

&lt;p&gt;thus our objective, mathematically can be described as;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;eq10.png&#34; alt=&#34;Equation 10&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;eq11.png&#34; alt=&#34;Equation 11&#34; /&gt;&lt;/p&gt;

&lt;p&gt;where ξi = ςi&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;This formulation is called the Soft margin technique.&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&#34;loss-function-interpretation-of-svm&#34;&gt;Loss Function Interpretation of SVM:&lt;/h3&gt;

&lt;p&gt;it can be interpreted that hinge loss is max(0,1-Zi).&lt;/p&gt;

&lt;p&gt;when Zi is ≥ 1 then the loss is 0.
when Zi &amp;lt; 1 then loss increases.&lt;/p&gt;

&lt;h3 id=&#34;what-is-kernel-trick&#34;&gt;What is Kernel trick?&lt;/h3&gt;

&lt;p&gt;Coming to the major part of the SVM for which it is most famous, the kernel trick. The kernel is a way of computing the dot product of two vectors x and y in some (very high dimensional) feature space, which is why kernel functions are sometimes called “generalized dot product.&lt;/p&gt;

&lt;p&gt;Applying kernel trick means just to the replace dot product of two vectors by the kernel function.&lt;/p&gt;

&lt;h3 id=&#34;using-the-support-vector-machines-for-non-linear-data-with-the-kernel-trick&#34;&gt;&lt;em&gt;Using the Support Vector Machines for non-linear data with the kernel trick&lt;/em&gt;&lt;/h3&gt;

&lt;p&gt;Until know we have talked about linear examples and how Support Vector Machines work and how you can implement them with sklearn in Python. I already talked a little bit about non-linear data. When there is a non-linear data set Support Vector Machines can not simply draw a linear hyperplane. Therefore Support Vector Machines use the kernel trick. When you have non-linear data, the kernel method helps you to find pattern and relations to reach a high accuracy in your final machine learning model.&lt;/p&gt;

&lt;h3 id=&#34;how-does-the-kernel-method-works&#34;&gt;&lt;em&gt;How does the Kernel method works?&lt;/em&gt;&lt;/h3&gt;

&lt;p&gt;The kernel method are contains are so called kernel function. These function map the non-linear separable input space into a higher dimensional linear separable feature space. And in this new higher dimensional linear separable feature space Support Vector Machines can work as normal. The kernel method then maps the solutions back, so that in the non-linear separable input space you then have a non-linear solution.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;kernel.png&#34; alt=&#34;kernel Trick &#34; /&gt;&lt;/p&gt;

&lt;p&gt;In the example above we have a two dimensional feature space, which is non-linear. With the kernel function we can map the input space into a three dimensional feature space. In this feature space we then can separate the training set linear. When we map the solution back to the input space we get a non-linear solution.&lt;/p&gt;

&lt;h3 id=&#34;pros-and-cons-of-svm&#34;&gt;Pros and cons of SVM:&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;Pros:&lt;/em&gt;&lt;/strong&gt;
* It is really effective in the higher dimension
* Effective when the number of features are more than training examples
* Best algorithm when classes are separable
* The hyperplane is affected by only the support vectors thus outliers have less impact
* SVM is suited for extreme case binary classification
&lt;strong&gt;&lt;em&gt;cons:&lt;/em&gt;&lt;/strong&gt;
* For larger dataset, it requires a large amount of time to process
* Does not perform well in case of overlapped classes
* Selecting, appropriately hyperparameters of the SVM that will allow for sufficient generalization performance
* Selecting the appropriate kernel function can be tricky&lt;/p&gt;

&lt;h3 id=&#34;preparing-data-for-svm&#34;&gt;Preparing data for SVM:&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;Numerical Conversion:
SVM assumes that you have inputs are numerical instead of categorical. So you can convert them using one of the most commonly used “one hot encoding , label-encoding etc”.&lt;/li&gt;
&lt;li&gt;Binary Conversion:
Since SVM is able to classify only binary data so you would need to convert the multi-dimensional dataset into binary form using (one vs the rest method / one vs one method) conversion method.&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;references&#34;&gt;REFERENCES:&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://cs229.stanford.edu/notes/cs229-notes3.pdf&#34; target=&#34;_blank&#34;&gt;http://cs229.stanford.edu/notes/cs229-notes3.pdf&lt;/a&gt; (Andrew Ng’s notes on SVM)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html&#34; target=&#34;_blank&#34;&gt;https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html&lt;/a&gt; (Sklearn page on SVM)&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Genome sequencing</title>
      <link>https://shreshthsaini.github.io/post/genome-sequencing/</link>
      <pubDate>Mon, 19 Aug 2019 00:00:00 +0530</pubDate>
      <guid>https://shreshthsaini.github.io/post/genome-sequencing/</guid>
      <description>

&lt;h3 id=&#34;what-is-genome-sequencing&#34;&gt;What is Genome Sequencing?&lt;/h3&gt;

&lt;p&gt;Genome sequencing or DNA sequencing refers to the process of determining the complete sequence of nucleotides in genome (read DNA). Ignoring the 3 dimensional orientation of the DNA strand, DNA can be thought of as a linear sequence of 4 nucleotide base pairs (bp), namely Adenine (A), Thymine (T), Guanine (G), Cytosine (C). &lt;em&gt;A pairs with T&lt;/em&gt; and &lt;em&gt;G pairs with C&lt;/em&gt;. Sequencing allows us to determine the sequence such as &lt;em&gt;AATGCCAT&amp;hellip;.&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&#34;why-is-sequencing-important&#34;&gt;Why is sequencing important?&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;Have you heard of Precision Medicine (PM)?&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Think about it this way, everytime you face a serious medical issue, instead of prescribing generic medicine/treatment procedures which is given to all the patient with similar symptoms, you get a prescription tailored for you, by analysing your genetic code and symptoms. The exact same treatment for exact same symptoms on me and you might have different outcomes, it may not be pleasant for one of us.&lt;/p&gt;

&lt;p&gt;Now to enable precision medicine, one of the key steps is to create profile for the patient, which is where sequencing comes into picture. Therfore it is important to invest and develope sequencing methods which have higher accuracies and are faster and cheaper.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;check out &lt;a href=&#34;https://www.facebook.com/Upworthy/videos/1560690857391553/&#34; target=&#34;_blank&#34;&gt;this video&lt;/a&gt; for one success story of precision medicine&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&#34;how-is-sequencing-done&#34;&gt;How is sequencing done?&lt;/h3&gt;

&lt;p&gt;Attempts to sequence DNA dates back to &lt;strong&gt;1970s&lt;/strong&gt; (&lt;a href=&#34;https://en.wikipedia.org/wiki/DNA_sequencing#History&#34; target=&#34;_blank&#34;&gt;wikipedia link to brief history&lt;/a&gt;). Intital techniques, even though impressive were quite costly and terribly slow for real world applications such as using it for human genome. Humans have come a long way now, both time and costs to sequence whole genome has come down drastically and now it&amp;rsquo;s practical to think about genome sequencing as part of diagnostics.&lt;/p&gt;

&lt;p&gt;Recent techniques are known as &lt;strong&gt;&lt;em&gt;NGS (Next Generation Sequencing)&lt;/em&gt;&lt;/strong&gt; or &lt;strong&gt;&lt;em&gt;HTS (High Throughput Sequencing)&lt;/em&gt;&lt;/strong&gt;. In the following I will discuss one successful commercial technique used today. While reading up on this topic I realised that the literature around this topic is presented with alot of fancy words (that made no sense to me and will probably not make sense to average joe). But then the topic is quite specific and not meant for avaerage joe, however to grasp things I found it helpful to look around for the meaning of fancy words as they help in providing context and fill in the gaps. I will try to present it in a simple language with links to resources where necessary.&lt;/p&gt;

&lt;h4 id=&#34;dna-nanoball-sequencing&#34;&gt;&lt;em&gt;DNA Nanoball Sequencing&lt;/em&gt;&lt;/h4&gt;

&lt;p&gt;Many of the sequencing method will broadly involve steps such as&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;splitting the DNA strand into smaller pieces&lt;/li&gt;
&lt;li&gt;generating multiple copies of the smaller pieces&lt;/li&gt;
&lt;li&gt;processing the cluster of smaller pieces with &lt;strong&gt;&lt;em&gt;marker nucleotides&lt;/em&gt;&lt;/strong&gt; which are fluorescent and are color coded depending upon the nucleotide&lt;/li&gt;
&lt;li&gt;capturing the image/data&lt;/li&gt;
&lt;li&gt;bioinformatics on data to extract sequences&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The specifics of each of the steps depend upon the method used. In &lt;strong&gt;&lt;em&gt;DNA Nanoball Sequencing&lt;/em&gt;&lt;/strong&gt; the longer DNA strands are &lt;strong&gt;&lt;em&gt;sonicated (using sound)&lt;/em&gt;&lt;/strong&gt; to break them into smaller pieces, then pieces of appropriate lengths (typically &lt;em&gt;400-500 bp&lt;/em&gt;) are chosen for futher processing (how it&amp;rsquo;s done is irrelevant for the conceptual big picture).&lt;/p&gt;

&lt;p&gt;Here is a cool video showing the sonification process&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=3GXD4NBm818&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://img.youtube.com/vi/3GXD4NBm818/0.jpg&#34; alt=&#34;IMAGE ALT TEXT HERE&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Nest step involves attaching &lt;a href=&#34;https://en.wikipedia.org/wiki/Adapter_(genetics)&#34; target=&#34;_blank&#34;&gt;adapter sequences&lt;/a&gt; and to convert the small fragments into curcular struture which is then replicated by a procedure call &lt;strong&gt;&lt;em&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Rolling_circle_replication&#34; target=&#34;_blank&#34;&gt;Rolling circle replication&lt;/a&gt;&lt;/em&gt;&lt;/strong&gt;. The output of this step leads to lot of circular copies which when linearised, forms a long strand of DNA, because of the adapter sequences (desinged to be &amp;ldquo;sticky&amp;rdquo;) the long strand folds onto itself making a ball like structure which is about &lt;em&gt;300nm&lt;/em&gt; in diameter. These nanoballs are then attached to a specially constructed microarray, nanoballs are arranged in highly ordered fashion hence are densly packed which is what allows the massive parallel processing.
One way to think about these arrays:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://upload.wikimedia.org/wikipedia/commons/5/5a/DNA_nanoball_Array.jpg&#34; alt=&#34;microarray1&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The sequencing part is easier to analyse with the unchained visualisation, that is consider the image of long DNA strand from the nanoball, we know the adapter sequences which we attached earlier, so we can construct an &amp;ldquo;anchor&amp;rdquo; sequence which will attach to the adapter part of the long template strand.&lt;/p&gt;

&lt;p&gt;Now we introduce, something called &amp;ldquo;&lt;strong&gt;&lt;em&gt;probes&lt;/em&gt;&lt;/strong&gt;&amp;rdquo;, these are short sequences with &amp;ldquo;&lt;strong&gt;&lt;em&gt;degenerate (not important)&lt;/em&gt;&lt;/strong&gt;&amp;rdquo; nucleotides in &lt;em&gt;all but one position&lt;/em&gt;, and have a color coded floroscence depending upon that one non-denerate nucleotide (for example in the image, &lt;em&gt;A&lt;/em&gt; is red, &lt;em&gt;C&lt;/em&gt; is yellow, &lt;em&gt;G&lt;/em&gt; is green, &lt;em&gt;T&lt;/em&gt; is blue).&lt;/p&gt;

&lt;p&gt;Anchor is attached to the adapter sequence, the microarray cell is flooded with &lt;strong&gt;&lt;em&gt;one type of probes (say non-degenrate nucleotide at one position to the left of adapter part)&lt;/em&gt;&lt;/strong&gt;, only the probe containing the complimentary non-degenrate nucleotide will bind, we can wash away the redundant chemicals and record the florocent signals, the color will indicate which one of the &lt;em&gt;A/T/G/C&lt;/em&gt; was present at that location. We can wash away the anchor and probe of this round and repeat the process with probes of different locations. As described nicely in this image and its caption :&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://upload.wikimedia.org/wikipedia/commons/thumb/4/48/Unchained_Ligation_Sequencing.png/800px-Unchained_Ligation_Sequencing.png&#34; alt=&#34;ligated sequencing&#34; /&gt;
&lt;em&gt;1. Single strand of DNA from a DNA nanoball 2. Attach complementary anchor to known adapter sequence 3. Add probe set #1 and DNA Ligase to interrogate position #1 to the left of the anchor. Only the complementary probe binds 4. Wash away all unbound probes and Ligase, and read the color of the fluorophore 5. Denature anchor and probe from DNA nanoball and add another anchor 6. Add probe set #2 and DNA ligase to interrogate position #2 to the left of the anchor. Repeat.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;This is an iterative process, where after every round of probe/ligation step, excessive chemicals are washed and the fluorocence is captured in form of a image. These images are then analysed to infer the sequence of the template strand using the colour coding scheme of the nucleotides.&lt;/p&gt;

&lt;p&gt;I chose this method because it is at the crux of commecial product by &lt;strong&gt;&lt;em&gt;&lt;a href=&#34;https://www.bgi.com/global/&#34; target=&#34;_blank&#34;&gt;Beijing Genomics Institute (BGI)&lt;/a&gt;&lt;/em&gt;&lt;/strong&gt;. Their method is known as &lt;strong&gt;&lt;a href=&#34;http://www.seq500.com/en/portal/Seq-500.shtml&#34; target=&#34;_blank&#34;&gt;Combinatorial probe anchor synthesis (cPAS)&lt;/a&gt;&lt;/strong&gt;, the technology is capable of processing around &lt;strong&gt;&lt;em&gt;40 million nucleotides per second&lt;/em&gt;&lt;/strong&gt; (as of 2018, which is a remarkable number)&lt;/p&gt;

&lt;h3 id=&#34;references&#34;&gt;References&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.genomenewsnetwork.org/resources/whats_a_genome/Chp2_1.shtml&#34; target=&#34;_blank&#34;&gt;http://www.genomenewsnetwork.org/resources/whats_a_genome/Chp2_1.shtml&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.ebi.ac.uk/training/online/course/ebi-next-generation-sequencing-practical-course/what-you-will-learn/what-next-generation-dna-&#34; target=&#34;_blank&#34;&gt;https://www.ebi.ac.uk/training/online/course/ebi-next-generation-sequencing-practical-course/what-you-will-learn/what-next-generation-dna-&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/DNA_sequencing&#34; target=&#34;_blank&#34;&gt;https://en.wikipedia.org/wiki/DNA_sequencing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/DNA_nanoball_sequencing&#34; target=&#34;_blank&#34;&gt;https://en.wikipedia.org/wiki/DNA_nanoball_sequencing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.seq500.com/en/portal/Seq-500.shtml&#34; target=&#34;_blank&#34;&gt;http://www.seq500.com/en/portal/Seq-500.shtml&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Sonication&#34; target=&#34;_blank&#34;&gt;https://en.wikipedia.org/wiki/Sonication&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.creative-biogene.com/blog/index.php/2016/11/01/brief-introduction-on-three-generations-of-genome-sequencing-technology/&#34; target=&#34;_blank&#34;&gt;https://www.creative-biogene.com/blog/index.php/2016/11/01/brief-introduction-on-three-generations-of-genome-sequencing-technology/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://koreabizwire.com/scientists-find-whole-genome-sequencing-of-korean-individual/67503&#34; target=&#34;_blank&#34;&gt;http://koreabizwire.com/scientists-find-whole-genome-sequencing-of-korean-individual/67503&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
  </channel>
</rss>
