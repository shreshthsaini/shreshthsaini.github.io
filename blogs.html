<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Shreshth Saini · Field Notes</title>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="description" content="Thinking Machines-inspired essays and research updates from Shreshth Saini on generative AI, HDR video, and perceptual intelligence.">
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&family=Space+Grotesk:wght@400;500;600;700&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="stylesheet.css">
  <link rel="icon" type="image/jpg" href="images/UT_profile.png">
</head>
<body>
  <div class="page-shell">
    <header class="site-header">
      <a href="index.html" class="brand">
        <span class="brand-mark">SS</span>
        <span class="brand-text">
          <span class="brand-title">Shreshth Saini</span>
          <span class="brand-subtitle">Generative AI • Perceptual Quality</span>
        </span>
      </a>
      <nav class="site-nav">
        <a href="index.html#about">About</a>
        <a href="index.html#updates">Updates</a>
        <a href="index.html#experience">Experience</a>
        <a href="index.html#services">Service</a>
        <a href="index.html#research">Research</a>
        <a href="index.html#projects">Projects</a>
        <a href="index.html#contact">Contact</a>
        <a href="blogs.html" class="nav-button">Blog</a>
      </nav>
    </header>

    <main>
      <section class="panel panel-hero">
        <div class="blog-hero">
          <p class="eyebrow">Field notes</p>
          <h1 class="hero-title">Stories on building perceptual, generative, and HDR-native intelligence.</h1>
          <p class="hero-lede">I document experiments, collaborations, and design choices that shape my research journey. Expect narrative-heavy write-ups—blending metrics with intuition—delivered in a Thinking Machines-inspired editorial voice.</p>
        </div>
      </section>

      <section class="panel">
        <div class="blog-grid">
          <article class="blog-card">
            <span class="blog-meta">Sept 2025 · Generative Models</span>
            <h3>Rectified-CFG++: Aligning flow-guided sampling with human perception</h3>
            <p>Behind the experiments that let Rectified Flow models adaptively adjust classifier-free guidance, closing the loop between semantic alignment and sample fidelity.</p>
            <a href="https://shreshthsaini.github.io/Rectified-CFGpp/">Read the story</a>
          </article>

          <article class="blog-card">
            <span class="blog-meta">Jun 2025 · Diffusion QA</span>
            <h3>Latent guidance and the future of perceptual evaluation</h3>
            <p>How LGDM uses diffusion priors to encode perceptual consistency, why that matters for IQA metrics, and what it unlocks for applied reliability.</p>
            <a href="data/camera_ready_LGDM.pdf">Dive into the research</a>
          </article>

          <article class="blog-card">
            <span class="blog-meta">May 2025 · HDR Video</span>
            <h3>BrightRate: Giving creators a compass for user-generated HDR</h3>
            <p>Designing a benchmark and metric that capture the wild variability of UGC HDR—from low-light capture quirks to platform delivery constraints.</p>
            <a href="https://brightvqa.github.io/BrightVQ/">Explore BrightRate</a>
          </article>

          <article class="blog-card">
            <span class="blog-meta">May 2025 · Dataset Design</span>
            <h3>CHUG: Crowdsourcing perceptual truth at HDR scale</h3>
            <p>Capturing 40K+ subjective ratings for HDR videos, orchestrating global data collection, and turning it into a living benchmark for quality assessment.</p>
            <a href="https://shreshthsaini.github.io/CHUG/">See the dataset</a>
          </article>

          <article class="blog-card">
            <span class="blog-meta">Mar 2025 · Lab Culture</span>
            <h3>Why LIVE needed an Assistant Director</h3>
            <p>Reflecting on the mentorship, operations, and community scaffolding required to keep a high-velocity research lab inclusive and ambitious.</p>
            <a href="https://live.ece.utexas.edu/">Visit LIVE</a>
          </article>

          <article class="blog-card">
            <span class="blog-meta">Jan 2024 · Research Internships</span>
            <h3>Engineering diffusion robustness at Alibaba</h3>
            <p>Building evaluation pipelines for diffusion-based IQA, and tuning models to stay consistent across domains and capture conditions.</p>
            <a href="https://www.alibabagroup.com/en/global/home">Read the recap</a>
          </article>
        </div>

        <details class="details-block" open>
          <summary>Archive</summary>
          <div class="blog-grid">
            <article class="blog-card">
              <span class="blog-meta">Jun 2024 · Applied Science</span>
              <h3>Inside Amazon’s perception team: toward Prime-EditBench</h3>
              <p>What it takes to align diffusion-based editing with the realities of global marketplaces, and the benchmarks we built to measure progress.</p>
              <a href="https://www.amazon.science/">Read the recap</a>
            </article>

            <article class="blog-card">
              <span class="blog-meta">Nov 2023 · HDR Quality</span>
              <h3>Contrastive HDR-VQA and the hunt for perceptual invariants</h3>
              <p>Design principles behind leveraging contrastive learning to predict HDR video quality without losing sight of subtle luminance cues.</p>
              <a href="https://openaccess.thecvf.com/content/WACV2024W/VAQ/papers/Saini_HIDRO-VQA_High_Dynamic_Range_Oracle_for_Video_Quality_Assessment_WACVW_2024_paper.pdf">Read the paper</a>
            </article>

            <article class="blog-card">
              <span class="blog-meta">Jun 2023 · Subjective Studies</span>
              <h3>Running the first large-scale HDR perceptual study</h3>
              <p>Operational lessons from coordinating thousands of Amazon Mechanical Turk participants to capture authentic HDR quality judgments.</p>
              <a href="https://www.mturk.com/">Study logistics</a>
            </article>

            <article class="blog-card">
              <span class="blog-meta">Aug 2022 · Graduate Life</span>
              <h3>Joining UT Austin and the LIVE Lab</h3>
              <p>How moving to Austin and working with Prof. Bovik reshaped my research lens on generative systems and perceptual evaluation.</p>
              <a href="https://www.ece.utexas.edu/">Read more</a>
            </article>
          </div>
        </details>
      </section>
    </main>

    <footer>
      © 2025 Shreshth Saini. Thanks for reading.
    </footer>
  </div>
</body>
</html>
